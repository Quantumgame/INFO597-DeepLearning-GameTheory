{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N Player Game\n",
    "## Iterated Peace War Game\n",
    "\n",
    "![](./figs/PW-display.png)\n",
    "I've created a version of the peace war game. The scenario for this game is members of lcdm own companies across the united states.\n",
    "\n",
    "Companies in this game have 3 actions: *peace*, *compromise*, or *war*. If a company (or agent) chooses peace they are looking for peaceful solutions with rival agents. If an agent chooses comprimise they are willing to find some middle ground but have taken certain precautions to ensure that they are in a better position if a rival agent chooses war. If an agent chooses war they are willing to inflict harm to other agents in order to achieve a greater payoff than the other 2 actions. The Payoff matrix for 2 players:\n",
    "![PW.png](./figs/PW.png)\n",
    "\n",
    "\n",
    "The Payoff matrices for 3 players are below:\n",
    "![PW-p.png](./figs/PW-p.png)\n",
    "This payoff matrix contains the utility values of all possible outcomes if the 3rd agent chooses the peace action.\n",
    "\n",
    "![PW-c.png](./figs/PW-c.png)\n",
    "This payoff matrix contains the utility values of all possible outcomes if the 3rd agent chooses the compromise action.\n",
    "\n",
    "![PW-w.png](./figs/PW-w.png)\n",
    "This payoff matrix contains the utility values of all possible outcomes if the 3rd agent chooses the war action.\n",
    "\n",
    "I could continue to write to write payoff matrices up to N Players however it becomes tedious to represent possible states using payoff matrices, so [game trees](https://wiki.scratch.mit.edu/wiki/Game_Tree) are usually used for iterated or N Player Games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gmaps, os  # Used for interactive visualizations\n",
    "from game_types import NPlayerGame\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring stuff for visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmaps.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "locs = [\n",
    "    [(37.760851, -122.443118), (37.760853, -122.443120)],  # Silcon Valley\n",
    "    [(40.092034, -88.238687), (40.092035, -88.238688)],  # Urbana\n",
    "    [(25.777052, -80.194957), (25.777054, -80.194959)],  # Flordia\n",
    "    [(40.705773, -74.010861), (40.705774, -74.010863)],  # Manhattan\n",
    "    [(35.898512, -78.865059), (35.898513, -78.865060)],  #  NC\n",
    "    [(42.278052, -83.738997), (42.278053, -83.738998)],  # Michigan\n",
    "    [(35.844058, -106.287484), (35.844059, -106.287485)],  # New Mexico\n",
    "    [(33.745074, -84.390840), (33.745076, -84.390842)],  # Georgia\n",
    "    [(32.758009, -96.805532), (32.758011, -96.805534)],  # Texas\n",
    "    [(47.653022, -122.305569), (47.653024, -122.305571)],  # Washington\n",
    "    [(47.653532, -100.347697), (47.653533, -100.347698)],  # ND\n",
    "    [(34.069110, -118.246972), (34.069112, -118.246974)],  # Sol Cal\n",
    "    [(44.723362, -111.071472), (44.723363, -111.071473)]  # WY\n",
    "]\n",
    "names = ['Silcon Valley', 'Illinois', 'Flordia', 'Manhattan', 'North Carolina',\n",
    "         'Michigan', 'New Mexico', 'Georgia', 'Texas', 'Washington', 'North Dakota', 'Sol Cal', 'Wyoming']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing Peace War Game with 14 Players for 650,000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name MLP/MLP_input_layer/W_0:0 is illegal; using MLP/MLP_input_layer/W_0_0 instead.\n",
      "INFO:tensorflow:Summary name MLP/MLP_input_layer/W_0:0/gradients is illegal; using MLP/MLP_input_layer/W_0_0/gradients instead.\n",
      "INFO:tensorflow:Summary name MLP/MLP_input_layer/b:0 is illegal; using MLP/MLP_input_layer/b_0 instead.\n",
      "INFO:tensorflow:Summary name MLP/MLP_input_layer/b:0/gradients is illegal; using MLP/MLP_input_layer/b_0/gradients instead.\n",
      "INFO:tensorflow:Summary name MLP/MLP_input_layer_copy/W_0:0 is illegal; using MLP/MLP_input_layer_copy/W_0_0 instead.\n",
      "INFO:tensorflow:Summary name MLP/MLP_input_layer_copy/b:0 is illegal; using MLP/MLP_input_layer_copy/b_0 instead.\n",
      "WARNING:tensorflow:From /Users/jarvis/GoogleDrive/education/UIUC_GRAD/coursework/INFO_597/summer-2017/INFO597-DeepLearning-GameTheory/NPlayerGames/strategies/machine_learning.py:36: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Playing Game:   0%|          | 0/650000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing Game: 100%|██████████| 650000/650000 [3:28:38<00:00, 51.92it/s]  \n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "game = NPlayerGame(n_players=14) # Create 13 agents of random type\n",
    "game.play(650000) # Play 600,000 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing scores of each agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent_name, agent_score = [], []\n",
    "for agent in game.data:\n",
    "    if agent != 'id':\n",
    "        agent_name.append(agent)\n",
    "        agent_score.append(sum(game.data[agent]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting current score number range to smaller range maintaining ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "old_range = max(agent_score) - min(agent_score)\n",
    "new_range = 35\n",
    "new_agent_scores = []\n",
    "for old_val in agent_score:\n",
    "    new_agent_scores.append( (((old_val-min(agent_score))*new_range)/old_range) + 10 ) \n",
    "#print(old_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Scores and Summary of Game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51c94b46d784d779b5a5f6a1c92970d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = []\n",
    "fig = gmaps.Map()\n",
    "#print('Agent Name \\t\\t\\t| Location  \\t\\t\\t|  Total Score')\n",
    "for i, loc in enumerate(locs):\n",
    "    #print('{0} \\t\\t\\t| {1} \\t\\t\\t| \\t\\t{2}'.format(agent_name[i], names[i], new_agent_scores[i]))\n",
    "    _layer = gmaps.heatmap_layer(loc, point_radius=int(new_agent_scores[i]))\n",
    "    fig.add_layer(_layer)\n",
    "d ={'Agent Name': agent_name, 'Location': names, 'Total Score': agent_score, 'Radius Size': new_agent_scores}\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The Interactive Map may not be rendered on Github)\n",
    "![](./figs/m-results.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agent Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Radius Size</th>\n",
       "      <th>Total Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agent1_grim</td>\n",
       "      <td>Silcon Valley</td>\n",
       "      <td>44.999946</td>\n",
       "      <td>1299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agent2_titfortat</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>44.999946</td>\n",
       "      <td>1299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agent3_cooperate</td>\n",
       "      <td>Flordia</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agent4_chaos</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>27.499085</td>\n",
       "      <td>974983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agent5_defect</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>agent6_titfortat</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>44.999946</td>\n",
       "      <td>1299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agent7_cooperate</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>agent8_deepqlearn</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>44.961392</td>\n",
       "      <td>1299283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>agent9_defect</td>\n",
       "      <td>Texas</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>agent10_chaos</td>\n",
       "      <td>Washington</td>\n",
       "      <td>27.510285</td>\n",
       "      <td>975191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>agent11_grim</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>44.999946</td>\n",
       "      <td>1299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>agent12_pavlov</td>\n",
       "      <td>Sol Cal</td>\n",
       "      <td>44.999946</td>\n",
       "      <td>1299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>agent14_grim</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>44.999946</td>\n",
       "      <td>1299999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Agent Name        Location  Radius Size  Total Score\n",
       "0         agent1_grim   Silcon Valley    44.999946      1299999\n",
       "1    agent2_titfortat        Illinois    44.999946      1299999\n",
       "2    agent3_cooperate         Flordia    10.000000       650000\n",
       "3        agent4_chaos       Manhattan    27.499085       974983\n",
       "4       agent5_defect  North Carolina    45.000000      1300000\n",
       "5    agent6_titfortat        Michigan    44.999946      1299999\n",
       "6    agent7_cooperate      New Mexico    10.000000       650000\n",
       "7   agent8_deepqlearn         Georgia    44.961392      1299283\n",
       "8       agent9_defect           Texas    45.000000      1300000\n",
       "9       agent10_chaos      Washington    27.510285       975191\n",
       "10       agent11_grim    North Dakota    44.999946      1299999\n",
       "11     agent12_pavlov         Sol Cal    44.999946      1299999\n",
       "12       agent14_grim         Wyoming    44.999946      1299999"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
